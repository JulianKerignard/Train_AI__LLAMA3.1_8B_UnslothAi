# incremental_training.py
# Version optimis√©e pour l'entra√Ænement incr√©mental

import os
import torch
import argparse
from datasets import load_from_disk, Dataset
import gc
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments
from transformers import Trainer, DataCollatorForLanguageModeling
from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model
from transformers import BitsAndBytesConfig
from datetime import datetime
import time
import shutil


# Analyse des arguments
def parse_args():
    parser = argparse.ArgumentParser(description="Entra√Ænement incr√©mental")
    parser.add_argument("--dataset_folder", type=str, default="tokenized_data_0_5000", help="Dossier des donn√©es")
    parser.add_argument("--batch_size", type=int, default=4, help="Taille du batch")
    parser.add_argument("--gradient_accumulation", type=int, default=4, help="Accumulation")
    parser.add_argument("--max_length", type=int, default=500, help="Longueur max")
    parser.add_argument("--lora_rank", type=int, default=8, help="Rang LoRA")
    parser.add_argument("--max_steps", type=int, default=300, help="√âtapes max")
    parser.add_argument("--learning_rate", type=float, default=5e-4, help="Taux d'apprentissage")
    parser.add_argument("--output_dir", type=str, default="optimized_lora_model", help="Dossier de sortie")
    parser.add_argument("--save_dir", type=str, default=None,
                        help="Dossier de sauvegarde (pour ne pas √©craser le mod√®le)")
    return parser.parse_args()


# Fonction pour nettoyer la m√©moire
def clean_memory():
    gc.collect()
    torch.cuda.empty_cache() if torch.cuda.is_available() else None
    print("üßπ M√©moire nettoy√©e")


# Point d'entr√©e principal
def main():
    args = parse_args()

    # Configurer le dossier de sortie
    if args.save_dir:
        save_dir = args.save_dir
    else:
        save_dir = args.output_dir

    os.makedirs(save_dir, exist_ok=True)

    # Afficher la configuration
    print("\n‚ö° ENTRA√éNEMENT INCR√âMENTAL SUR RTX 3080 ‚ö°")
    print(f"Batch size: {args.batch_size}, Accumulation: {args.gradient_accumulation}")
    print(f"Max length: {args.max_length}, √âtapes: {args.max_steps}")
    print(f"Learning rate: {args.learning_rate}")
    print(f"Donn√©es: {args.dataset_folder}")
    print(f"Sauvegarde: {save_dir}")

    # === √âTAPE 1: CHARGEMENT DES DONN√âES ===
    print("\nüîç √âTAPE 1: CHARGEMENT DES DONN√âES")
    try:
        # Chemin des donn√©es
        tokenized_data_path = os.path.join(args.output_dir, "prepared_data", args.dataset_folder)

        if os.path.exists(tokenized_data_path):
            print(f"Chargement des donn√©es depuis {tokenized_data_path}...")
            tokenized_dataset = load_from_disk(tokenized_data_path)
            print(f"Donn√©es charg√©es: {len(tokenized_dataset)} exemples")

            # V√©rification des donn√©es
            sample = tokenized_dataset[0]
            print(f"Longueur de s√©quence: {len(sample['input_ids'])}")

            # Si les s√©quences sont trop longues, les tronquer
            if len(sample['input_ids']) > args.max_length:
                print(f"Troncation des s√©quences √† {args.max_length} tokens...")

                # Cr√©er une copie tronqu√©e
                truncated_dataset = []
                for example in tokenized_dataset:
                    truncated_example = {
                        'input_ids': example['input_ids'][:args.max_length],
                        'attention_mask': example['attention_mask'][:args.max_length],
                        'labels': example['labels'][:args.max_length]
                    }
                    truncated_dataset.append(truncated_example)

                tokenized_dataset = Dataset.from_list(truncated_dataset)
                print(f"Donn√©es tronqu√©es: {len(tokenized_dataset)} exemples")
        else:
            print(f"‚ùå Donn√©es non trouv√©es dans {tokenized_data_path}")
            print("Veuillez v√©rifier le nom du dossier de donn√©es")
            exit(1)

        clean_memory()
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement des donn√©es: {e}")
        exit(1)

    # === √âTAPE 2: CR√âATION D'UN NOUVEAU MOD√àLE ===
    print("\nüîß √âTAPE 2: CR√âATION D'UN NOUVEAU MOD√àLE")
    try:
        # Charger le tokenizer
        print("Chargement du tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained("unsloth/llama-3-8b-bnb-4bit")
        tokenizer.pad_token = tokenizer.eos_token

        # Configuration de quantification optimis√©e
        print("Configuration de quantification optimis√©e...")
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_use_double_quant=True,
            bnb_4bit_quant_type="nf4",
            bnb_4bit_compute_dtype=torch.float16
        )

        # Options communes pour le mod√®le
        model_kwargs = {
            "device_map": "auto",
            "torch_dtype": torch.float16,
            "quantization_config": bnb_config,
        }

        # Charger un nouveau mod√®le
        print("Chargement d'un nouveau mod√®le de base...")
        model = AutoModelForCausalLM.from_pretrained(
            "unsloth/llama-3-8b-bnb-4bit", **model_kwargs
        )

        # Pr√©parer pour LoRA
        print("Pr√©paration pour LoRA...")
        model = prepare_model_for_kbit_training(model)

        # Configuration LoRA
        peft_config = LoraConfig(
            r=args.lora_rank,
            lora_alpha=16,
            target_modules=[
                "q_proj", "k_proj", "v_proj", "o_proj",
                "gate_proj", "up_proj", "down_proj"
            ],
            bias="none",
            lora_dropout=0.0,  # Pas de dropout pour plus de vitesse
            task_type="CAUSAL_LM",
        )
        model = get_peft_model(model, peft_config)

        # Si un mod√®le pr√©c√©dent existe, charger ses poids
        old_adapter_path = os.path.join(args.output_dir, "adapter_model.safetensors")
        if os.path.exists(old_adapter_path):
            print(f"Chargement des poids du mod√®le pr√©c√©dent depuis {old_adapter_path}...")
            # Utiliser le merge_and_unload pour charger les poids adaptateurs
            try:
                state_dict = torch.load(old_adapter_path)
                # Charger les poids adaptateurs
                missing, unexpected = model.load_state_dict(state_dict, strict=False)
                print(f"Chargement termin√©. {len(missing)} cl√©s manquantes, {len(unexpected)} inattendues")
            except Exception as e:
                print(f"Erreur lors du chargement des poids: {e}")
                print("Continuons avec un nouveau mod√®le...")

        # V√©rifier que le mod√®le est en mode entra√Ænement
        model.train()
        print("Mod√®le configur√© en mode entra√Ænement")

        # Afficher les param√®tres
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"Param√®tres totaux: {total_params:,}")
        print(f"Param√®tres entra√Ænables: {trainable_params:,} ({trainable_params / total_params:.2%})")

        # V√©rification des param√®tres entra√Ænables
        if trainable_params == 0:
            print("‚ùå ERREUR: Aucun param√®tre entra√Ænable!")
            exit(1)

        clean_memory()
    except Exception as e:
        print(f"‚ùå Erreur lors de la cr√©ation du mod√®le: {e}")
        exit(1)

    # === √âTAPE 3: CONFIGURATION DE L'ENTRA√éNEMENT ===
    print("\n‚öôÔ∏è √âTAPE 3: CONFIGURATION DE L'ENTRA√éNEMENT")
    try:
        # Dossier pour les checkpoints
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_dir = os.path.join(save_dir, f"checkpoint_{timestamp}")

        # Configuration optimis√©e pour la vitesse
        print("Configuration optimis√©e pour la vitesse...")
        training_args = TrainingArguments(
            output_dir=checkpoint_dir,
            per_device_train_batch_size=args.batch_size,
            gradient_accumulation_steps=args.gradient_accumulation,
            learning_rate=args.learning_rate,
            lr_scheduler_type="cosine",
            warmup_ratio=0.03,
            max_steps=args.max_steps,
            logging_steps=5,
            save_steps=50,
            save_total_limit=2,
            fp16=True,
            gradient_checkpointing=True,
            optim="adamw_torch",  # Plus stable que fused qui peut causer des erreurs
            weight_decay=0.01,
            max_grad_norm=1.0,
            report_to="none",
            dataloader_num_workers=2,
            dataloader_pin_memory=True,
            remove_unused_columns=False,
            disable_tqdm=False,
            seed=42
        )

        # Data collator optimis√©
        print("Configuration du data collator optimis√©...")
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=tokenizer,
            mlm=False
        )

        # Configuration du Trainer
        print("Configuration du Trainer optimis√©...")
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=tokenized_dataset,
            data_collator=data_collator,
            tokenizer=tokenizer
        )

        clean_memory()
    except Exception as e:
        print(f"‚ùå Erreur lors de la configuration de l'entra√Ænement: {e}")
        exit(1)

    # === √âTAPE 4: LANCEMENT DE L'ENTRA√éNEMENT ===
    print("\nüöÄ √âTAPE 4: LANCEMENT DE L'ENTRA√éNEMENT")
    try:
        # Afficher l'utilisation de la m√©moire
        if torch.cuda.is_available():
            gpu_mem_alloc = torch.cuda.max_memory_allocated() / 1024 ** 3
            gpu_mem_reserved = torch.cuda.max_memory_reserved() / 1024 ** 3
            print(f"M√©moire GPU avant entra√Ænement: {gpu_mem_alloc:.2f} GB allou√©s, {gpu_mem_reserved:.2f} GB r√©serv√©s")

        # D√©marrer l'entra√Ænement avec timer
        start_time = time.time()
        print(f"D√©marrage de l'entra√Ænement √† {datetime.now().strftime('%H:%M:%S')}...")

        # Afficher la configuration finale
        print(
            f"Configuration finale: batch={args.batch_size}*{args.gradient_accumulation}={args.batch_size * args.gradient_accumulation}, lr={args.learning_rate}")

        # D√©sactiver explicitement le cache pour √©viter les probl√®mes avec gradient checkpointing
        model.config.use_cache = False  # Important pour √©viter l'erreur "use_cache=True is incompatible with gradient checkpointing"

        # Lancer l'entra√Ænement
        trainer.train()

        # Calculer le temps √©coul√©
        elapsed_time = time.time() - start_time
        hours, remainder = divmod(elapsed_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        print(f"Entra√Ænement termin√© en {int(hours)}h {int(minutes)}m {int(seconds)}s")

        # Afficher l'utilisation finale de la m√©moire
        if torch.cuda.is_available():
            gpu_mem_alloc = torch.cuda.max_memory_allocated() / 1024 ** 3
            gpu_mem_reserved = torch.cuda.max_memory_reserved() / 1024 ** 3
            print(f"Pic de m√©moire GPU: {gpu_mem_alloc:.2f} GB allou√©s, {gpu_mem_reserved:.2f} GB r√©serv√©s")

        # Sauvegarder le mod√®le final
        print(f"Sauvegarde du mod√®le final dans {save_dir}...")
        trainer.save_model(save_dir)
        tokenizer.save_pretrained(save_dir)
        print(f"Mod√®le et tokenizer sauvegard√©s dans {save_dir}")

        # Cr√©er un fichier d'information
        with open(os.path.join(save_dir, "training_info.txt"), "w") as f:
            f.write(f"Entra√Ænement incr√©mental termin√© le {datetime.now()}\n")
            f.write(f"Dur√©e: {int(hours)}h {int(minutes)}m {int(seconds)}s\n")
            f.write(f"Exemples: {len(tokenized_dataset)} (dossier {args.dataset_folder})\n")
            f.write(
                f"Configuration: batch={args.batch_size}*{args.gradient_accumulation}, lr={args.learning_rate}, steps={args.max_steps}\n")
    except Exception as e:
        print(f"‚ùå Erreur pendant l'entra√Ænement: {e}")
        # Tenter de sauvegarder quand m√™me
        try:
            print("Tentative de sauvegarde malgr√© l'erreur...")
            trainer.save_model(save_dir)
            tokenizer.save_pretrained(save_dir)
            print(f"Mod√®le sauvegard√© dans {save_dir}")
        except Exception as e2:
            print(f"‚ùå Impossible de sauvegarder: {e2}")

    print("\n‚úÖ ENTRA√éNEMENT INCR√âMENTAL TERMIN√â")
    print(f"Mod√®le disponible dans: {save_dir}")
    print(f"Pour continuer l'entra√Ænement avec d'autres donn√©es:")
    print(f"  python {__file__} --dataset_folder autre_dossier_de_donn√©es")


if __name__ == "__main__":
    main()